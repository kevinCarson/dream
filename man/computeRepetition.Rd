% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rem_repetition_deprecatedV100.R
\name{computeRepetition}
\alias{computeRepetition}
\title{Compute Butts' (2008) Repetition Network Statistic for Event Dyads in a Relational Event Sequence}
\usage{
computeRepetition(
  observed_time,
  observed_sender,
  observed_receiver,
  processed_time,
  processed_sender,
  processed_receiver,
  sliding_windows = FALSE,
  processed_seqIDs = NULL,
  halflife = 2,
  counts = FALSE,
  dyadic_weight = 0,
  window_size = NA,
  Lerneretal_2013 = FALSE
)
}
\arguments{
\item{observed_time}{The vector of event times from the pre-processing event sequence.}

\item{observed_sender}{The vector of event senders from the pre-processing event sequence.}

\item{observed_receiver}{The vector of event receivers from the pre-processing event sequence}

\item{processed_time}{The vector of event times from the post-processing event sequence (i.e., the event sequence that contains the observed and null events).}

\item{processed_sender}{The vector of event senders from the post-processing event sequence (i.e., the event sequence that contains the observed and null events).}

\item{processed_receiver}{The vector of event receivers from the post-processing event sequence (i.e., the event sequence that contains the observed and null events).}

\item{sliding_windows}{TRUE/FALSE. TRUE indicates that the sliding windows computational approach will
be used to compute the resulting network statistic, while FALSE indicates the approach will not be used. Set
to FALSE by default. It’s important to note that the sliding windows framework should only be used
when the pre-processed event sequence is ‘big’, such as the 360 million pre-processed event sequence
used in Lerner and Lomi (2020), as it aims to reduce the computational burden of sorting ‘big’ datasets. In general,
most pre-processed event sequences will not need to use the sliding windows
approach. There is not a strict cutoff for ‘big’ dataset. This definition depends on both the
size of the observed event sequence and the post-processing sampling dataset. For instance,
according to our internal tests, when the event sequence is relatively large (i.e., 100,000
observed events) with probability of sampling from the observed event sequence set to 0.05
and using 10 controls per sampled event, the sliding windows framework for computing repetition
is about 11\% faster than the non-sliding windows framework. Yet, in a smaller dataset
(i.e., 10,000 observed events) the sliding windows framework is about 25\% slower than the
non-sliding framework with the same conditions as before.}

\item{processed_seqIDs}{If sliding_windows is set to TRUE, the vector of event sequence IDs from the post-processing event sequence. The event sequence IDs represents the index for when the event occurred in the observed event sequence (e.g., the 5th event in the sequence will have a value of 5 in this vector).}

\item{halflife}{A numerical value that is the halflife value to be used in the exponential weighting function (see details section). Preset to 2 (should be updated by the user based on substantive context).}

\item{counts}{TRUE/FALSE. TRUE indicates that the counts of past events should be computed (see the details section). FALSE indicates that the temporal exponential weighting function should be used to downweigh past events (see the details section). Set to FALSE by default.}

\item{dyadic_weight}{A numerical value for the dyadic cutoff weight that represents the numerical cutoff value for temporal relevancy based on the exponential weighting function. For example, a numerical value of 0.01, indicates that an exponential weight less than 0.01 will become 0 and that events with such value (or smaller values) will not be included in the sum of the past event weights (see the details section). Set to 0 by default.}

\item{window_size}{If sliding_windows is set to TRUE, the sizes of the windows that are used for the sliding windows computational framework. If NA, the function internally divides the dataset into ten slices (may not be optimal).}

\item{Lerneretal_2013}{TRUE/FALSE. TRUE indicates that the Lerner et al. (2013) exponential weighting function will be used (see the details section). FALSE indicates that the Lerner and Lomi (2020) exponential weighting function will be used (see the details section). Set to FALSE by default}
}
\value{
The vector of repetition statistics for the relational event sequence.
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#deprecated}{\figure{lifecycle-deprecated.svg}{options: alt='[Deprecated]'}}}{\strong{[Deprecated]}}

\code{computeRepetition()} has been deprecated starting on version 1.0.0 of the \code{dream} package. Please use the \code{remstats_repetition()} function and see the \code{NEWS.md} file for more details.

This function computes the repetition network sufficient statistic for a relational event
sequence (see Lerner and Lomi 2020; Butts 2008). Repetition measures the increased tendency
for events between S and R to occur given that S and R have interacted
in the past. Furthermore, this measure allows for repetition scores to be only
computed for the sampled events, while creating the weights based on the full event
sequence (see Lerner and Lomi 2020; Vu et al. 2015). The function allows users to use two different weighting functions,
reduce computational runtime, employ a sliding windows framework for large relational sequences, and
specify a dyadic cutoff for relational relevancy.
}
\details{
This function calculates the repetition scores for relational event models
based on the exponential weighting function used in either Lerner and Lomi
(2020) or Lerner et al. (2013).

Following Lerner and Lomi (2020), the exponential weighting function in
relational event models is:
\deqn{w(s, r, t) = e^{-(t-t') \cdot \frac{ln(2)}{T_{1/2}} }}

Following Lerner et al. (2013), the exponential weighting function in
relational event models is:
\deqn{w(s, r, t) = e^{-(t-t') \cdot \frac{ln(2)}{T_{1/2}} } \cdot \frac{ln(2)}{T_{1/2}}}

In both of the above equations, \emph{s} is the current event sender, \emph{r} is the
current event receiver (target), \emph{t} is the current event time, \emph{t'} is the
past event times that meet the weight subset (in this case, all events that
have the same sender and receiver), and \eqn{T_{1/2}} is the halflife parameter.

The formula for repetition for event \eqn{e_i} is:
\deqn{repetition_{e_{i}} = w(s, r, t) }

Moreover, researchers interested in modeling temporal relevancy (see Quintane,
Mood, Dunn, and Falzone 2022; Lerner and Lomi 2020) can specify the dyadic
weight cutoff, that is, the minimum value for which the weight is considered
relationally relevant. Users who do not know the specific dyadic cutoff value to use, can use the
\code{\link{computeRemDyadCut}} function.

Following Butts (2008), if the counts of the past events are requested, the formula for repetition for
event \eqn{e_i} is:
\deqn{repetition_{e_{i}} = d(s = s', r = r', t') }
Where, \eqn{d()} is the number of past events where the event sender, \emph{s'}, is the current event sender, \emph{s}, the event
receiver (target), \emph{r'}, is the current event receiver, \emph{r}. Moreover, the counting equation
can be used in tandem with relational relevancy, by specifying the halflife parameter, exponential
weighting function, and the dyadic cut off weight values. If the user is not interested in modeling
relational relevancy, then those value should be left at their baseline values.
}
\examples{
data("WikiEvent2018.first100k")
WikiEvent2018 <- WikiEvent2018.first100k[1:10000,] #the first ten thousand events
WikiEvent2018$time <- as.numeric(WikiEvent2018$time) #making the variable numeric
### Creating the EventSet By Employing Case-Control Sampling With M = 5 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- processTMEventSeq(
 data = WikiEvent2018, # The Event Dataset
 time = WikiEvent2018$time, # The Time Variable
 eventID = WikiEvent2018$eventID, # The Event Sequence Variable
 sender = WikiEvent2018$user, # The Sender Variable
 receiver = WikiEvent2018$article, # The Receiver Variable
 p_samplingobserved = 0.01, # The Probability of Selection
 n_controls = 5, # The Number of Controls to Sample from the Full Risk Set
 seed = 9999) # The Seed for Replication
#### Estimating Repetition Scores Without the Sliding Windows Framework
EventSet$rep <- computeRepetition(
   observed_time = WikiEvent2018$time,
   observed_sender = WikiEvent2018$user,
   observed_receiver = WikiEvent2018$article,
   processed_time = EventSet$time,
   processed_sender = EventSet$sender,
   processed_receiver = EventSet$receiver,
   halflife = 2.592e+09, #halflife parameter
   dyadic_weight = 0,
   Lerneretal_2013 = FALSE)

EventSet$sw_rep <- computeRepetition(
   observed_time = WikiEvent2018$time,
   observed_sender = WikiEvent2018$user,
   observed_receiver = WikiEvent2018$article,
   processed_time = EventSet$time,
   processed_sender = EventSet$sender,
   processed_receiver = EventSet$receiver,
   processed_seqIDs = EventSet$sequenceID,
   halflife = 2.592e+09, #halflife parameter
   dyadic_weight = 0,
   sliding_window = TRUE,
   Lerneretal_2013 = FALSE)

#The results with and without the sliding windows are the same (see correlation
#below). Using the sliding windows method is recommended when the data are
#big' so that memory allotment is more efficient.
cor(EventSet$sw_rep, EventSet$rep)

#### Estimating Repetition Scores with the Counts of Events Returned
EventSet$repC <- computeRepetition(
   observed_time = WikiEvent2018$time,
   observed_sender = WikiEvent2018$user,
   observed_receiver = WikiEvent2018$article,
   processed_time = EventSet$time,
   processed_sender = EventSet$sender,
   processed_receiver = EventSet$receiver,
   halflife = 2.592e+09, #halflife parameter
   dyadic_weight = 0,
   Lerneretal_2013 = FALSE,
   counts = TRUE)

cbind(EventSet$rep,
     EventSet$sw_rep,
     EventSet$repC)


}
\references{
Butts, Carter T. 2008. "A Relational Event Framework for Social Action." \emph{Sociological Methodology} 38(1): 155-200.

Quintane, Eric, Martin Wood, John Dunn, and Lucia Falzon. 2022. “Temporal
Brokering: A Measure of Brokerage as a Behavioral Process.” \emph{Organizational Research Methods}
25(3): 459-489.

Lerner, Jürgen and Alessandro Lomi. 2020. “Reliability of relational event
model estimates under sampling: How to fit a relational event model to 360
million dyadic events.” \emph{Network Science} 8(1): 97-135.

Lerner, Jürgen, Margit Bussman, Tom A.B. Snijders, and Ulrik Brandes. 2013. "
Modeling Frequency and Type of Interaction in Event Networks."
\emph{The Corvinus Journal of Sociology and Social Policy} 4(1): 3-32.

Vu, Duy, Philippa Pattison, and Garry Robins. 2015. "Relational event models for social learning in MOOCs." \emph{Social Networks} 43: 121-135.
}
\author{
Kevin A. Carson \href{mailto:kacarson@arizona.edu}{kacarson@arizona.edu}, Diego F. Leal \href{mailto:dflc@arizona.edu}{dflc@arizona.edu}
}
