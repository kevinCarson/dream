(x^2)
0.269*x-0.007*(x^2)
y - y[0:length(y)-1]
y[100:2] - y[99:1]
y1<- 0.269*x
y2 <- -0.007*(x^2)
plot(x,y1)
plot(x,y2)
library(redr)
help(package = "redr")
help(package = "igraph")
help(package = "sna")
??redr
help(package = "redr")
library(marginaleffects)
library(foreign)
library(marginaleffects)
library(ggplot2)
# NOTE: For details and exs of the marginaleffects package see:
#       https://marginaleffects.com/
######################################################
# 0 - Load data and clean
######################################################
ah4 <- read.dta("https://tdmize.github.io/data/data/nli_ah4.dta")
ah4 <- subset(ah4, select=c(depB, role, woman, parrole, age, race, income, college))
# Drop any missing data on model variables
ah4_clean <- na.omit(ah4)
summary(ah4_clean)
######################################################
# 1 - Nominal X Continuous Interaction
######################################################
mod31 <- glm(depB ~ woman*role + parrole + age + race + income + college,
data = ah4_clean, family=binomial(link='logit'))
summary(mod31)
# AME of roles for each gender (avg_slopes calculates instantaneous change)
avg_slopes(mod31, variables = "role", by = "woman")
# Test AME equality w/ hypothesis option
avg_slopes(mod31, hypothesis = "b1 - b2 = 0", variables = "role", by = "woman")
# Test gender gap at each role count
avg_comparisons(mod31, variables = "woman", by = "role")
avg_comparisons(mod31, variables = "woman", by = "role")$estimate
mean(avg_comparisons(mod31, variables = "woman", by = "role")$estimate)
# Customize with ggplot functions
fig14 + theme_minimal() +
ggtitle("Probability of being depressive by social role count and gender") +
xlab("Social role count") + ylab("Pr(Depressive)") +
scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +
scale_y_continuous(limits = c(0, .7), breaks = seq(0, .7, by = .1))
######################################################
# 2 - Plots of predictions (Figure 14)
######################################################
fig14 <- plot_predictions(mod31, condition = c("role", "woman"))
fig14
# Customize with ggplot functions
fig14 + theme_minimal() +
ggtitle("Probability of being depressive by social role count and gender") +
xlab("Social role count") + ylab("Pr(Depressive)") +
scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +
scale_y_continuous(limits = c(0, .7), breaks = seq(0, .7, by = .1))
######################################################
## Bonus plot of gender gaps at each role count
######################################################
fig_gaps <- plot_comparisons(mod31, variables = "woman", by = "role")
fig_gaps
# Customize with ggplot functions
fig_gaps + theme_minimal() +
ggtitle("Gender gap in probability of being depressive at different role counts") +
xlab("Count of social roles") + ylab("Effect of Gender: Women - Men") +
scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 1)) +
scale_y_continuous(limits = c(-.2, .2), breaks = seq(-.2, .2, by = .1)) +
geom_hline(yintercept = 0) +
labs(caption = "Effects above zero indciate women have higher probabilites of being depressive")
avg_slopes(mod31, variables = "role", by = "woman")
# Test AME equality w/ hypothesis option
avg_slopes(mod31, hypothesis = "b1 - b2 = 0", variables = "role", by = "woman")
-0.0347 - - 0.0312
######################################################
# 3- Kevin Code
######################################################
ame1 <- summary(margins::margins(mod31, variables = "role", at = list(woman = 1)))
ame2 <- summary(margins::margins(mod31, variables = "role", at = list(woman = 0)))
mod31
table(ah4_clean$woman)
######################################################
# 3- Kevin Code
######################################################
ame1 <- summary(margins::margins(mod31, variables = "role", at = list(woman = Woman)))
######################################################
# 3- Kevin Code
######################################################
ame1 <- summary(margins::margins(mod31, variables = "role", at = list(woman = "Woman")))
ame2 <- summary(margins::margins(mod31, variables = "role", at = list(woman = "Man")))
ame1
rbind(ame1,ame2)
# AME of roles for each gender (avg_slopes calculates instantaneous change)
avg_slopes(mod31, variables = "role", by = "woman")
rbind(ame1[1,],ame2[1,])
######################################################
# 3- Kevin Code
######################################################
ame1 <- summary(margins::margins(mod31, variables = "role", at = list(woman = "Woman")))[1,]
ame2 <- summary(margins::margins(mod31, variables = "role", at = list(woman = "Man")))[1,]
rbind(ame1,ame2)
compare.margins(margins=c(ame1$AME,ame2$AME), #AME estimates
margins.ses=c(ame1$SE,ame2$SE),  #AME Standard Errors
seed = 9999, #Seed for replication
rounded = 4) #Round the p-value estimate
######################################################
# 3- Kevin Code
######################################################
library(catregs)
ame1 <- summary(margins::margins(mod31, variables = "role", at = list(woman = "Woman")))[1,]
ame2 <- summary(margins::margins(mod31, variables = "role", at = list(woman = "Man")))[1,]
rbind(ame1,ame2)
compare.margins(margins=c(ame1$AME,ame2$AME), #AME estimates
margins.ses=c(ame1$SE,ame2$SE),  #AME Standard Errors
seed = 9999, #Seed for replication
rounded = 4) #Round the p-value estimate
rbind(ame1,ame2)
# Test gender gap at each role count
avg_comparisons(mod31, variables = "woman", by = "role")
# Test AME equality w/ hypothesis option
avg_slopes(mod31, hypothesis = "b1 - b2 = 0", variables = "role", by = "woman")
compare.margins(margins=c(ame1$AME,ame2$AME), #AME estimates
margins.ses=c(ame1$SE,ame2$SE),  #AME Standard Errors
seed = 9999, #Seed for replication
rounded = 4) #Round the p-value estimate
compare.margins(margins=c(ame2$AME,ame1$AME), #AME estimates
margins.ses=c(ame2$SE,ame1$SE),  #AME Standard Errors
seed = 9999, #Seed for replication
rounded = 4) #Round the p-value estimate
# Test gender gap at each role count
avg_comparisons(mod31, variables = "woman", by = "role")
# Test AME equality w/ hypothesis option
avg_slopes(mod31, hypothesis = "b1 - b2 = 0", variables = "role", by = "woman")
compare.margins(margins=c(ame2$AME,ame1$AME), #AME estimates
margins.ses=c(ame2$SE,ame1$SE),  #AME Standard Errors
seed = 9999, #Seed for replication
rounded = 4) #Round the p-value estimate
rbind(ame1,ame2)
ame2$AME-ame1$AME
# AME of roles for each gender (avg_slopes calculates instantaneous change)
avg_slopes(mod31, variables = "role", by = "woman")
-0.0347 -  -0.0312
ame2$AME
compare.margins(margins=round(c(ame2$AME,ame1$AME),4), #AME estimates
margins.ses=c(ame2$SE,ame1$SE),  #AME Standard Errors
seed = 9999, #Seed for replication
rounded = 4) #Round the p-value estimate
compare.margins(margins=round(c(ame1$AME,ame2$AME),4), #AME estimates
margins.ses=c(ame1$SE,ame2$SE),  #AME Standard Errors
seed = 9999, #Seed for replication
rounded = 4) #Round the p-value estimate
# AME of roles for each gender (avg_slopes calculates instantaneous change)
avg_slopes(mod31, variables = "role", by = "woman")
rbind(ame1,ame2)
ame1$SE
ame2$SE
k <- avg_slopes(mod31, variables = "role", by = "woman")
k$std.error
# Test gender gap at each role count
avg_comparisons(mod31, variables = "woman", by = "role")
?marginaleffect::avg_slopes
mod31 <- glm(depB ~ woman*role + parrole + age + race + income + college,
data = ah4_clean, family=binomial(link='logit'))
summary(mod31)
# AME of roles for each gender (avg_slopes calculates instantaneous change)
avg_slopes(mod31, variables = "role", by = "woman")
# Test AME equality w/ hypothesis option
avg_slopes(mod31, hypothesis = "b1 - b2 = 0", variables = "role", by = "woman")
ame1 <- summary(margins::margins(mod31, variables = "role", at = list(woman = "Woman")))[1,]
ame2 <- summary(margins::margins(mod31, variables = "role", at = list(woman = "Man")))[1,]
rbind(ame1,ame2)
compare.margins(margins=round(c(ame1$AME,ame2$AME),4), #AME estimates
margins.ses=c(ame1$SE,ame2$SE),  #AME Standard Errors
seed = 9999, #Seed for replication
rounded = 4) #Round the p-value estimate
# Test AME equality w/ hypothesis option
avg_slopes(mod31, hypothesis = "b1 - b2 = 0", variables = "role", by = "woman")
rbind(ame1,ame2)
-0.0310---0.0347
-0.0347 - -0.0310
mod31 <- glm(depB ~ woman*role + parrole + age + race + income + college,
data = ah4_clean, family=binomial(link='logit'))
summary(mod31)
# AME of roles for each gender (avg_slopes calculates instantaneous change)
avg_slopes(mod31, variables = "role", by = "woman")
?avg_slopes
?rem::degreeStat
rem.stat.repetitionNEW <- function(observed_time, # variable (column) name that contains the time variable
observed_sender, # variable (column) name that contains the sender variable
observed_receiver, # variable (column) name that contains the receiver variable
processed_time,
processed_sender, # variable (column) name that contains the sender variable
processed_receiver, # variable (column) name that contains the receiver variable
sliding_windows = FALSE, # TRUE = we want to use the sliding windows framework
processed_seqIDs = NULL, #If true, the user should insert the placement of sampled events in the original file
halflife, # the half life value for the weighting function
dyadic_weight, # dyadic cutoff weight for events that no longer matter
window_size = NA, # the sizes of the windows that we will use, if NA, we will compute it internally
Lerneretal_2013 = FALSE # Do we want to use the weighting function of Lerner et al. 2013 (alsoused in the rem R package)?
) {
#base::cat("Checking Data Structure and User Inputs.......") # outputting status to user
########################################################
#
#   Checking for Errors in User Inputs
#
########################################################
n_forrealevents <- base::length(observed_time) #the number of real events provided by user
n_forsampledevents <- base::length(process_time)#the number of sampled events provided by user
if (length(observed_time) != n_forrealevents) { # if the length of the time vector is not the same as the full dataset
base::stop("Error: The length of the provided events time is not the same length as the events dataset") # stop computation and tell the user
}
if (length(observed_sender) != n_forrealevents) { # if the length of the time vector is not the same as the full dataset
base::stop("Error: The length of the provided events sender is not the same length as the events dataset") # stop computation and tell the user
}
if (length(observed_receiver) != n_forrealevents) { # if the length of the time vector is not the same as the full dataset
base::stop("Error: The length of the provided events receiver is not the same length as the events dataset") # stop computation and tell the user
}
if (length(process_time) != n_forsampledevents) { # if the length of the time vector is not the same as the full dataset
base::stop("Error: The length of the provided eventSet time is not the same length as the sampld events dataset") # stop computation and tell the user
}
if (length(process_sender) != n_forsampledevents) { # if the length of the time vector is not the same as the full dataset
base::stop("Error: The length of the provided eventSet sender is not the same length as the sampld events dataset") # stop computation and tell the user
}
if (length(process_receiver) != n_forsampledevents) { # if the length of the time vector is not the same as the full dataset
base::stop("Error: The length of the provided eventSet receiver is not the same length as the sampld events dataset") # stop computation and tell the user
}
if(sliding_windows == TRUE & is.null(process_seqIDs)){
base::stop("Error: Sliding windows was specified to be true, however, the process_seqIDs argument is missing. Please add this and restart the function!") # stop computation and tell the user
}
if(sliding_windows == TRUE & length(process_seqIDs) != n_forsampledevents){
base::stop("Error: The process_seqIDs argument is not the same length as the process_sender vector.") # stop computation and tell the user
}
########################################################
# Renaming the columns to match the user inputs
########################################################
events <- data.table::data.table(sender = observed_sender,# renaming the sender column
receiver = observed_receiver, # renaming the receiver column
time = observed_time)# renaming the time column
eventSet <- data.table::data.table(sender = process_sender,# renaming the sender column
receiver = process_receiver, # renaming the receiver column
time = process_time)# renaming the time column
########################################################
#### Clearing User Inputs for Memory
########################################################
rm(list = c("observed_time", "observed_sender", "observed_receiver",
"process_time", "process_sender", "process_receiver"))
########################################################
#
#    If the User Did not want to use the sliding windows framework
#
########################################################
if (sliding_windows == FALSE) {
#base::cat("Starting computation of repetition scores without the sliding windows framework.......") # outputting status to user
n_observed_events <- nrow(eventSet) # number of observed events in dataset
repetition <- numeric(n_observed_events) # empty vector to store computed statistics
for (i in 1:n_observed_events) { # for all observed events in the dataset
senderi <- eventSet$sender[i] ####  current user for event i
receiveri <- eventSet$receiver[i] ####  current article for event i
timei <- eventSet$time[i] ####  current time for event i
####### For repetition!
repetitioni <- data.table::`[.data.table`(events, sender == senderi & receiver == receiveri)
if(collapse::fnrow(repetitioni) == 0){next}
repetitioni <- data.table::`[.data.table`(repetitioni, time < timei)
if(collapse::fnrow(repetitioni) == 0){next}
# repetitioni <- repetitioni[,weight := weight(current = timei, past = time, halflife = halflife,  dyadic_weight = dyadic_weight, Lerneretal_2013 = Lerneretal_2013) ]
repetitioni$weight <- redr:::weight(current = timei, past = repetitioni$time, halflife = halflife, dyadic_weight = dyadic_weight, Lerneretal_2013 = Lerneretal_2013)
repetition[i] <- sum(repetitioni$weight)  # add the sum of the past event weights to the ith spot in the inertia vector
rm(list = c("repetitioni"))
}
}
########################################################
#
#    If the User Did Want To Use the Sliding Windows Framework
#
########################################################
if (sliding_windows == TRUE) {
#base::cat("Setting up data structure for the sliding windows framework.......") # outputting status to user
if (is.na(window_size)) {
window_size <- round(nrow(events) / 10) # an estimate of the window size of the dataset is simply dividing it into 10 datasets
}
##### Given how R handles odd and even sequences, we have to internally check if the number of events is even odd
starting_blocks <- seq(from = 1, to = nrow(events), by = window_size)
ending_blocks <- seq(from = window_size, to = nrow(events), by = window_size)
if (length(starting_blocks) != length(ending_blocks)) {
ending_blocks <- c(ending_blocks, nrow(events))
}
sliding_window <- data.table::data.table(
start_block = starting_blocks,
stop_block = ending_blocks
)
#### Computing the minimum effective event time for each sampled event (event time that exceeds relational relevancy)
#### see minimum_effective_time()
if(dyadic_weight == 0){
eventSet$minimum_event <- 0 #no minimum event time since dyadic weight is 0
}else{
#compute dyadic weight
eventSet[, minimum_event := redr:::minimum_effective_time(
eventtime = time, dyadicweight = dyadic_weight,
halflife = halflife, Lerneretal_2013 = Lerneretal_2013
)]
}
###### Doing a quick test: it should be noted that too large of a halflife parameter in the Lerner et al. 2013
###### weighting function results in minimum effective time greater than the eventTime. Therefore, it cannot be
###### properly approximated in this case.
test_vec <- eventSet$minimum_event - eventSet$time # getting the difference between the values, these should all be negative
areanygreater <- collapse::fsum((test_vec) > 0) # checking if we have any positive values,
if (areanygreater != 0) { # if we do, stop the function, and tell the user this
base::stop("Error: Unfortunately the combination of the provided halflife parameter and the weighting function (i.e., using the \n
Lerner et al. 2013 specification) resulted in a minimum effective time that is greater than the eventTimes, therefore, \n
the sliding windows framework cannot be used. Please restart with sliding_windows == FALSE. Please see the documentation \n
for this function and the minimum effective time documentation. As always, we hope you know what you're doing.....") # stop computation and tell the user
}
######################################################################
####### Creating the Vector to Store Event Weights
######################################################################
n_observed_events <- nrow(eventSet) # number of observed events in dataset
repetition <- numeric(n_observed_events) # empty vector to store computed statistics
eventIDS <- process_seqIDs # the sampled eventnet IDS
######################################################################
####### Computing Statistics on a Sliding Frame Method
######################################################################
#base::cat("Starting computation of repetition scores with sliding windows framework.......") # outputting status to user
n_blocks <- nrow(sliding_window) # the number of sliding windows
for (j in 1:n_blocks) { # go through each of the blocks (i.e., subsetting the datamatrix to only handle
# an arbitrary number of rows at a time)
######################################################################
####### Subsetting full event sequence based on sliding window sizes
######################################################################
eventsj <- events[sliding_window$start_block[j]:sliding_window$stop_block[j]]
########################################################
#
#   Comment: Eventually allow the user to add the working directory and file name encase the WikiEvent dataset is being used
#
########################################################
### for jumping ahead in a moving frame
### the sampled event has occured before the current blocks, then skip
### this is because event statistics are not computed for future events
### only the network of past events
ifelse(j == 1, new_start <- 1,
new_start <- base::min(which(eventIDS >= sliding_window$start_block[j]))
)
if(new_start == Inf){ #if there is no longer a need to continue moving through the dataset
break #break from the sliding windows inner for loop
}
ifelse(j == n_blocks, n_sampled <- nrow(eventSet),
n_sampled <- suppressWarnings(base::min(which(eventSet$minimum_event >= max(eventsj$time)))) - 1 # max possible event is the minimum minus 1, since minimum will have a weight of zero
)
ifelse(n_sampled == Inf, n_sampled <- nrow(eventSet), n_sampled)
for (i in new_start:n_sampled) { # for i in all sampled events
senderi <- eventSet$sender[i] ####  current user for event i
receiveri <- eventSet$receiver[i] ####  current article for event i
timei <- eventSet$time[i] ####  current time for event i
####### For repetition!
repetitioni <- eventsj[sender == senderi & receiver == receiveri] # all events that have the current article and user
if(collapse::fnrow(repetitioni) == 0){next}
repetitioni <- repetitioni[time < timei] ### for all events that occurred before the current, compute the weight with a dyadic cutoff at dyadic_weighti
if(collapse::fnrow(repetitioni) == 0){next}
repetitioni$weight <- redr:::weight(current = timei, past = repetitioni$time, halflife = halflife, dyadic_weight = dyadic_weight, Lerneretal_2013 = Lerneretal_2013)
# repetitioni$weight <-  weight(current = timei, past = time, halflife = halflife,  dyadic_weight = dyadic_weight, Lerneretal_2013 = Lerneretal_2013)
repetition[i] <- sum(repetitioni$weight) + repetition[i] # add the sum of the past event weights to the ith spot in the inertia vector
###### clearing memory for consumption purposes
rm(list = c("senderi", "receiveri", "timei", "repetitioni"))
}
rm(list = c("eventsj"))
}
}
########################################################
#
#   Returning the values back to the user
#
########################################################
return(repetition)# return the vector of values
}
15/4
devtools::load_all()
help(package = "redr")
data("southern_women")
southern_women
rm(list = ls())
setwd("/Users/kevincarson/Dropbox/Research_Projects/Leal_Carson_RA/R_Package/redr/data")
load("WikiEvent2018.first100k.rda")
ls()
WikiEvent2018.first100k
load("WikiEvent2018.first100k.rda")
lapply(WikiEvent2018.first100k, typeof)
WikiEvent2018.first100k$time
WikiEvent2018.first100k,
WikiEvent2018.first100k=
WikiEvent2018.first100k$time <- as.double(WikiEvent2018.first100k$time )
WikiEvent2018.first100k$time
library(redr)
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
EventSet
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
data("WikiEvent2018.first100k")
### Creating the EventSet By Employing Case-Control Sampling With M = 10 and
### Sampling from the Observed Event Sequence with P = 0.01
EventSet <- rem.riskset.tm(
data = WikiEvent2018.first100k, # The Event Dataset
time = WikiEvent2018.first100k$time, # The Time Variable
eventID = WikiEvent2018.first100k$eventID, # The Event Sequence Variable
sender = WikiEvent2018.first100k$user, # The Sender Variable
receiver = WikiEvent2018.first100k$article, # The Receiver Variable
p_samplingobserved = 0.01, # The Probability of Selection
n_controls = 10, # The Number of Controls to Sample from the Full Risk Set
seed = 9999
) #
EventSet
